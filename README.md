# 🤖 AI DevHelper (.NET + Ollama + Angular)

A simple yet powerful **local AI assistant for developers**, built with  
**.NET 8**, **Ollama**, and **Angular**.  

This project demonstrates how to integrate **Microsoft.Extensions.AI** with **Ollama** in a .NET backend, and connect it to an Angular frontend for a clean chat UI.  
Everything runs locally, ensuring **privacy and security**.

---

## ✨ Features

- 🔒 **Private by design** — all AI runs locally, no data leaves your machine.  
- 💬 **Angular chat UI** — ask questions and get answers from a local model.  
- 🧠 **Ollama integration** — powered by models like `llama3`, `mistral`, etc.  
- ⚡ **.NET backend** — uses familiar libraries (`Microsoft.Extensions.AI`, `OllamaSharp`).  
- 📂 **Extendable** — add embeddings to query your team’s codebase or docs.  

---

## 🛠️ Tech Stack

- [.NET 8](https://dotnet.microsoft.com/) — backend API  
- [ASP.NET Core Minimal API](https://learn.microsoft.com/aspnet/core)  
- [Angular 18](https://angular.dev/) — frontend SPA  
- [Ollama](https://ollama.ai) — local LLM runtime  
- [OllamaSharp](https://github.com/awaescher/OllamaSharp) — C# client for Ollama  
- [Microsoft.Extensions.AI](https://learn.microsoft.com/dotnet/ai/overview) — .NET AI abstractions  

---

## 📂 Project Structure

